{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/'\n",
    "DATA_PATH = os.path.abspath('./data/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform label\n",
    "def transform_dataframe_label(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    label_map = {\n",
    "        \"true\": \"true\",\n",
    "        \"false\": \"false\",\n",
    "        \"half-true\": \"true\",\n",
    "        \"pants-fire\": \"false\",\n",
    "        \"barely-true\": \"false\",\n",
    "        \"mostly-true\": \"true\",\n",
    "    }\n",
    "\n",
    "    df[\"label\"] = df[\"label\"].apply(lambda x: label_map[x])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(filter(lambda x: x.endswith('.tsv') ,os.listdir(DATA_PATH)))\n",
    "\n",
    "for file in files:\n",
    "    # Read and rename fields\n",
    "    df = pd.read_csv(os.path.join(DATA_PATH, file), sep='\\t', header=None)\n",
    "    df.columns = ['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context']\n",
    "\n",
    "    # transform raw file and save into csv format\n",
    "    df.to_csv(os.path.join(DATA_PATH, file.replace('.tsv', '_raw.csv')), index=False, header=True)\n",
    "    \n",
    "    df = transform_dataframe_label(df)\n",
    "    \n",
    "    # transform and save into csv format\n",
    "    df.to_csv(os.path.join(DATA_PATH, file.replace('.tsv', '.csv')), index=False, header=True)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "\n",
    "https://www.kaggle.com/code/sudalairajkumar/getting-started-with-text-preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text data\n",
    "df_text = df[['statement']].astype('str')\n",
    "df_text.columns = ['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>building a wall on the u.s.-mexico border will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wisconsin is on pace to double the number of l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>says john mccain has done nothing to help the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suzanne bonamici supports a plan that will cut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when asked by a reporter whether hes at the ce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  building a wall on the u.s.-mexico border will...\n",
       "1  wisconsin is on pace to double the number of l...\n",
       "2  says john mccain has done nothing to help the ...\n",
       "3  suzanne bonamici supports a plan that will cut...\n",
       "4  when asked by a reporter whether hes at the ce..."
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower casing\n",
    "df_text['text'] = df_text['text'].str.lower()\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove word in list\n",
    "def remove_words(text: str, removal_str: 'set[str]', is_char:bool = False) -> str:\n",
    "    if is_char:\n",
    "        return \"\".join([char for char in list(text) if char not in removal_str])\n",
    "    return \" \".join([word for word in text.split() if word not in removal_str])\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "cnt = Counter()\n",
    "for text in df_text[\"text\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "n_rare_words = 10\n",
    "\n",
    "# Preprocess pipeline the text form dataframe\n",
    "def text_preprocess(texts: 'pd.Series[str]') -> 'pd.Series[str]':\n",
    "    # Remove punctuation\n",
    "    PUNCT_TO_REMOVE = string.punctuation\n",
    "    texts = texts.apply(\n",
    "        lambda text: remove_words(text, set(PUNCT_TO_REMOVE), is_char=True)\n",
    "    )\n",
    "\n",
    "    STOPWORDS = set(stopwords.words(\"english\"))\n",
    "    FREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\n",
    "    RAREWORDS = set([w for (w, wc) in cnt.most_common()[: -n_rare_words - 1 : -1]])\n",
    "\n",
    "    removal_pipeline = [STOPWORDS, FREQWORDS, RAREWORDS]\n",
    "\n",
    "    for words in removal_pipeline:\n",
    "        texts = texts.apply(lambda text: remove_words(text, words))\n",
    "\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>building wall usmexico border take literally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wisconsin pace double number layoffs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>john mccain done nothing help vets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suzanne bonamici supports plan cut choice medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asked reporter whether hes center criminal sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>budget provides highest funding level history ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>ive almost every day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>early 1980s sen kennedy offered help leaders r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>epa permit new epa director got done two days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>governor going around talking fund income cut ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1267 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0          building wall usmexico border take literally\n",
       "1                  wisconsin pace double number layoffs\n",
       "2                    john mccain done nothing help vets\n",
       "3     suzanne bonamici supports plan cut choice medi...\n",
       "4     asked reporter whether hes center criminal sch...\n",
       "...                                                 ...\n",
       "1262  budget provides highest funding level history ...\n",
       "1263                               ive almost every day\n",
       "1264  early 1980s sen kennedy offered help leaders r...\n",
       "1265      epa permit new epa director got done two days\n",
       "1266  governor going around talking fund income cut ...\n",
       "\n",
       "[1267 rows x 1 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['text'] = text_preprocess(df_text['text'])\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>building wall usmexico border take literally</td>\n",
       "      <td>build wall usmexico border take liter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wisconsin pace double number layoffs</td>\n",
       "      <td>wisconsin pace doubl number layoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>john mccain done nothing help vets</td>\n",
       "      <td>john mccain done noth help vet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suzanne bonamici supports plan cut choice medi...</td>\n",
       "      <td>suzann bonamici support plan cut choic medicar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asked reporter whether hes center criminal sch...</td>\n",
       "      <td>ask report whether he center crimin scheme vio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0       building wall usmexico border take literally   \n",
       "1               wisconsin pace double number layoffs   \n",
       "2                 john mccain done nothing help vets   \n",
       "3  suzanne bonamici supports plan cut choice medi...   \n",
       "4  asked reporter whether hes center criminal sch...   \n",
       "\n",
       "                                        text_stemmed  \n",
       "0              build wall usmexico border take liter  \n",
       "1                 wisconsin pace doubl number layoff  \n",
       "2                     john mccain done noth help vet  \n",
       "3  suzann bonamici support plan cut choic medicar...  \n",
       "4  ask report whether he center crimin scheme vio...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "df_text[\"text_stemmed\"] = df_text[\"text\"].apply(lambda text: stem_words(text))\n",
    "df_text.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>building wall usmexico border take literally</td>\n",
       "      <td>build wall usmexico border take liter</td>\n",
       "      <td>building wall usmexico border take literally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wisconsin pace double number layoffs</td>\n",
       "      <td>wisconsin pace doubl number layoff</td>\n",
       "      <td>wisconsin pace double number layoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>john mccain done nothing help vets</td>\n",
       "      <td>john mccain done noth help vet</td>\n",
       "      <td>john mccain done nothing help vet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suzanne bonamici supports plan cut choice medi...</td>\n",
       "      <td>suzann bonamici support plan cut choic medicar...</td>\n",
       "      <td>suzanne bonamici support plan cut choice medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asked reporter whether hes center criminal sch...</td>\n",
       "      <td>ask report whether he center crimin scheme vio...</td>\n",
       "      <td>asked reporter whether he center criminal sche...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0       building wall usmexico border take literally   \n",
       "1               wisconsin pace double number layoffs   \n",
       "2                 john mccain done nothing help vets   \n",
       "3  suzanne bonamici supports plan cut choice medi...   \n",
       "4  asked reporter whether hes center criminal sch...   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0              build wall usmexico border take liter   \n",
       "1                 wisconsin pace doubl number layoff   \n",
       "2                     john mccain done noth help vet   \n",
       "3  suzann bonamici support plan cut choic medicar...   \n",
       "4  ask report whether he center crimin scheme vio...   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0       building wall usmexico border take literally  \n",
       "1                wisconsin pace double number layoff  \n",
       "2                  john mccain done nothing help vet  \n",
       "3  suzanne bonamici support plan cut choice medic...  \n",
       "4  asked reporter whether he center criminal sche...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "df_text['text_lemmatized'] = df_text['text'].apply(lambda text: lemmatize_words(text))\n",
    "df_text.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text data\n",
    "df_text = df[['statement']].astype('str')\n",
    "df_text.columns = ['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Obamacare insurance cooperative failures should be expected because theyre like any business, and when you start businesses in America, at the fifth year, half of the businesses have closed.'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df_text['text'][64]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>StartIndex</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>IsPunctuation</th>\n",
       "      <th>IsSpace</th>\n",
       "      <th>WordShape</th>\n",
       "      <th>PartOfSpeech</th>\n",
       "      <th>POSTag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obamacare</td>\n",
       "      <td>0</td>\n",
       "      <td>obamacare</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insurance</td>\n",
       "      <td>10</td>\n",
       "      <td>insurance</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cooperative</td>\n",
       "      <td>20</td>\n",
       "      <td>cooperative</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>failures</td>\n",
       "      <td>32</td>\n",
       "      <td>failure</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>should</td>\n",
       "      <td>41</td>\n",
       "      <td>should</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>AUX</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>be</td>\n",
       "      <td>48</td>\n",
       "      <td>be</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xx</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expected</td>\n",
       "      <td>51</td>\n",
       "      <td>expect</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>because</td>\n",
       "      <td>60</td>\n",
       "      <td>because</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>they</td>\n",
       "      <td>68</td>\n",
       "      <td>they</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>re</td>\n",
       "      <td>72</td>\n",
       "      <td>re</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xx</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>like</td>\n",
       "      <td>75</td>\n",
       "      <td>like</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>any</td>\n",
       "      <td>80</td>\n",
       "      <td>any</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxx</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>business</td>\n",
       "      <td>84</td>\n",
       "      <td>business</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>,</td>\n",
       "      <td>92</td>\n",
       "      <td>,</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>and</td>\n",
       "      <td>94</td>\n",
       "      <td>and</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxx</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>when</td>\n",
       "      <td>98</td>\n",
       "      <td>when</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>WRB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>you</td>\n",
       "      <td>103</td>\n",
       "      <td>you</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxx</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>start</td>\n",
       "      <td>107</td>\n",
       "      <td>start</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>businesses</td>\n",
       "      <td>113</td>\n",
       "      <td>business</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>in</td>\n",
       "      <td>124</td>\n",
       "      <td>in</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xx</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>America</td>\n",
       "      <td>127</td>\n",
       "      <td>America</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>,</td>\n",
       "      <td>134</td>\n",
       "      <td>,</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>at</td>\n",
       "      <td>136</td>\n",
       "      <td>at</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xx</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the</td>\n",
       "      <td>139</td>\n",
       "      <td>the</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxx</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>fifth</td>\n",
       "      <td>143</td>\n",
       "      <td>fifth</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>year</td>\n",
       "      <td>149</td>\n",
       "      <td>year</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>,</td>\n",
       "      <td>153</td>\n",
       "      <td>,</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>half</td>\n",
       "      <td>155</td>\n",
       "      <td>half</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>of</td>\n",
       "      <td>160</td>\n",
       "      <td>of</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xx</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>the</td>\n",
       "      <td>163</td>\n",
       "      <td>the</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxx</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>businesses</td>\n",
       "      <td>167</td>\n",
       "      <td>business</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>have</td>\n",
       "      <td>178</td>\n",
       "      <td>have</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>closed</td>\n",
       "      <td>183</td>\n",
       "      <td>close</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>.</td>\n",
       "      <td>189</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Text  StartIndex        Lemma  IsPunctuation  IsSpace WordShape  \\\n",
       "0     Obamacare           0    obamacare          False    False     Xxxxx   \n",
       "1     insurance          10    insurance          False    False      xxxx   \n",
       "2   cooperative          20  cooperative          False    False      xxxx   \n",
       "3      failures          32      failure          False    False      xxxx   \n",
       "4        should          41       should          False    False      xxxx   \n",
       "5            be          48           be          False    False        xx   \n",
       "6      expected          51       expect          False    False      xxxx   \n",
       "7       because          60      because          False    False      xxxx   \n",
       "8          they          68         they          False    False      xxxx   \n",
       "9            re          72           re          False    False        xx   \n",
       "10         like          75         like          False    False      xxxx   \n",
       "11          any          80          any          False    False       xxx   \n",
       "12     business          84     business          False    False      xxxx   \n",
       "13            ,          92            ,           True    False         ,   \n",
       "14          and          94          and          False    False       xxx   \n",
       "15         when          98         when          False    False      xxxx   \n",
       "16          you         103          you          False    False       xxx   \n",
       "17        start         107        start          False    False      xxxx   \n",
       "18   businesses         113     business          False    False      xxxx   \n",
       "19           in         124           in          False    False        xx   \n",
       "20      America         127      America          False    False     Xxxxx   \n",
       "21            ,         134            ,           True    False         ,   \n",
       "22           at         136           at          False    False        xx   \n",
       "23          the         139          the          False    False       xxx   \n",
       "24        fifth         143        fifth          False    False      xxxx   \n",
       "25         year         149         year          False    False      xxxx   \n",
       "26            ,         153            ,           True    False         ,   \n",
       "27         half         155         half          False    False      xxxx   \n",
       "28           of         160           of          False    False        xx   \n",
       "29          the         163          the          False    False       xxx   \n",
       "30   businesses         167     business          False    False      xxxx   \n",
       "31         have         178         have          False    False      xxxx   \n",
       "32       closed         183        close          False    False      xxxx   \n",
       "33            .         189            .           True    False         .   \n",
       "\n",
       "   PartOfSpeech POSTag  \n",
       "0           ADJ     JJ  \n",
       "1          NOUN     NN  \n",
       "2           ADJ     JJ  \n",
       "3          NOUN    NNS  \n",
       "4           AUX     MD  \n",
       "5           AUX     VB  \n",
       "6          VERB    VBN  \n",
       "7         SCONJ     IN  \n",
       "8          PRON    PRP  \n",
       "9          VERB    VBP  \n",
       "10          ADP     IN  \n",
       "11          DET     DT  \n",
       "12         NOUN     NN  \n",
       "13        PUNCT      ,  \n",
       "14        CCONJ     CC  \n",
       "15        SCONJ    WRB  \n",
       "16         PRON    PRP  \n",
       "17         VERB    VBP  \n",
       "18         NOUN    NNS  \n",
       "19          ADP     IN  \n",
       "20        PROPN    NNP  \n",
       "21        PUNCT      ,  \n",
       "22          ADP     IN  \n",
       "23          DET     DT  \n",
       "24          ADJ     JJ  \n",
       "25         NOUN     NN  \n",
       "26        PUNCT      ,  \n",
       "27         NOUN     NN  \n",
       "28          ADP     IN  \n",
       "29          DET     DT  \n",
       "30         NOUN    NNS  \n",
       "31          AUX    VBP  \n",
       "32         VERB    VBN  \n",
       "33        PUNCT      .  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "olist = []\n",
    "for token in doc:\n",
    "    l = [token.text,\n",
    "        token.idx,\n",
    "        token.lemma_,\n",
    "        token.is_punct,\n",
    "        token.is_space,\n",
    "        token.shape_,\n",
    "        token.pos_,\n",
    "        token.tag_]\n",
    "    olist.append(l)\n",
    "    \n",
    "odf = pd.DataFrame(olist)\n",
    "odf.columns= [\"Text\", \"StartIndex\", \"Lemma\", \"IsPunctuation\", \"IsSpace\", \"WordShape\", \"PartOfSpeech\", \"POSTag\"]\n",
    "odf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "866206d3ce38356be375f950e8c92408cdea91776d08b03ca687df0e81d3a33c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
