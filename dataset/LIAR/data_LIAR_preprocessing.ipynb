{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/'\n",
    "DATA_PATH = os.path.abspath('./data/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "# nlp = spacy.load('en_core_web_sm', disable= ['tok2vec', 'tagger', 'parser', 'senter', 'attribute_ruler', 'ner'])\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def spacy_preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    doc = nlp(df['statement'][0])\n",
    "    df['statement_processed'] = df['statement'].apply(lambda row: \" \".join(list(filter(None, [w.lemma_ if not w.is_stop and not w.is_punct else '' for w in nlp(row)]))))\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform label\n",
    "def transform_dataframe_label(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    label_map = {\n",
    "        \"true\": \"true\",\n",
    "        \"false\": \"false\",\n",
    "        \"half-true\": \"true\",\n",
    "        \"pants-fire\": \"false\",\n",
    "        \"barely-true\": \"false\",\n",
    "        \"mostly-true\": \"true\",\n",
    "    }\n",
    "\n",
    "    df[\"label\"] = df[\"label\"].apply(lambda x: label_map[x])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(filter(lambda x: x.endswith('.tsv') ,os.listdir(DATA_PATH)))\n",
    "\n",
    "for file in files:\n",
    "    # Read and rename fields\n",
    "    df = pd.read_csv(os.path.join(DATA_PATH, file), sep='\\t', header=None)\n",
    "    df.columns = ['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context']\n",
    "\n",
    "    # transform raw file and save into csv format\n",
    "    df.to_csv(os.path.join(DATA_PATH, file.replace('.tsv', '_raw.csv')), index=False, header=True)\n",
    "    \n",
    "    df = transform_dataframe_label(df)\n",
    "    df = spacy_preprocess(df)\n",
    "    \n",
    "    # transform and save into csv format\n",
    "    df.to_csv(os.path.join(DATA_PATH, file.replace('.tsv', '.csv')), index=False, header=True)\n",
    "    \n",
    "    df[df['label'] == 'true'].to_csv(os.path.join(DATA_PATH, file.replace('.tsv', '_true.csv')), index=False, header=True)\n",
    "    df[df['label'] != 'true'].to_csv(os.path.join(DATA_PATH, file.replace('.tsv', '_false.csv')), index=False, header=True)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "\n",
    "https://www.kaggle.com/code/sudalairajkumar/getting-started-with-text-preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text data\n",
    "df_text = df[['statement']].astype('str')\n",
    "df_text.columns = ['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>building a wall on the u.s.-mexico border will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wisconsin is on pace to double the number of l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>says john mccain has done nothing to help the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suzanne bonamici supports a plan that will cut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when asked by a reporter whether hes at the ce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  building a wall on the u.s.-mexico border will...\n",
       "1  wisconsin is on pace to double the number of l...\n",
       "2  says john mccain has done nothing to help the ...\n",
       "3  suzanne bonamici supports a plan that will cut...\n",
       "4  when asked by a reporter whether hes at the ce..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower casing\n",
    "df_text['text'] = df_text['text'].str.lower()\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove word in list\n",
    "def remove_words(text: str, removal_str: 'set[str]', is_char:bool = False) -> str:\n",
    "    if is_char:\n",
    "        return \"\".join([char for char in list(text) if char not in removal_str])\n",
    "    return \" \".join([word for word in text.split() if word not in removal_str])\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "cnt = Counter()\n",
    "for text in df_text[\"text\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "n_rare_words = 10\n",
    "\n",
    "# Preprocess pipeline the text form dataframe\n",
    "def text_preprocess(texts: 'pd.Series[str]') -> 'pd.Series[str]':\n",
    "    # Remove punctuation\n",
    "    PUNCT_TO_REMOVE = string.punctuation\n",
    "    texts = texts.apply(\n",
    "        lambda text: remove_words(text, set(PUNCT_TO_REMOVE), is_char=True)\n",
    "    )\n",
    "\n",
    "    STOPWORDS = set(stopwords.words(\"english\"))\n",
    "    FREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\n",
    "    RAREWORDS = set([w for (w, wc) in cnt.most_common()[: -n_rare_words - 1 : -1]])\n",
    "\n",
    "    removal_pipeline = [STOPWORDS, FREQWORDS, RAREWORDS]\n",
    "\n",
    "    for words in removal_pipeline:\n",
    "        texts = texts.apply(lambda text: remove_words(text, words))\n",
    "\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>building wall usmexico border take literally y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wisconsin pace double number layoffs year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>john mccain done nothing help vets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suzanne bonamici supports plan cut choice medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asked reporter whether hes center criminal sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>budget provides highest state funding level hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>ive almost every day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>early 1980s sen kennedy offered help leaders r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>epa permit new epa director got done two days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>governor going around state talking fund incom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1267 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     building wall usmexico border take literally y...\n",
       "1             wisconsin pace double number layoffs year\n",
       "2                    john mccain done nothing help vets\n",
       "3     suzanne bonamici supports plan cut choice medi...\n",
       "4     asked reporter whether hes center criminal sch...\n",
       "...                                                 ...\n",
       "1262  budget provides highest state funding level hi...\n",
       "1263                               ive almost every day\n",
       "1264  early 1980s sen kennedy offered help leaders r...\n",
       "1265      epa permit new epa director got done two days\n",
       "1266  governor going around state talking fund incom...\n",
       "\n",
       "[1267 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['text'] = text_preprocess(df_text['text'])\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>building wall usmexico border take literally y...</td>\n",
       "      <td>build wall usmexico border take liter year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wisconsin pace double number layoffs year</td>\n",
       "      <td>wisconsin pace doubl number layoff year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>john mccain done nothing help vets</td>\n",
       "      <td>john mccain done noth help vet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suzanne bonamici supports plan cut choice medi...</td>\n",
       "      <td>suzann bonamici support plan cut choic medicar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asked reporter whether hes center criminal sch...</td>\n",
       "      <td>ask report whether he center crimin scheme vio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  building wall usmexico border take literally y...   \n",
       "1          wisconsin pace double number layoffs year   \n",
       "2                 john mccain done nothing help vets   \n",
       "3  suzanne bonamici supports plan cut choice medi...   \n",
       "4  asked reporter whether hes center criminal sch...   \n",
       "\n",
       "                                        text_stemmed  \n",
       "0         build wall usmexico border take liter year  \n",
       "1            wisconsin pace doubl number layoff year  \n",
       "2                     john mccain done noth help vet  \n",
       "3  suzann bonamici support plan cut choic medicar...  \n",
       "4  ask report whether he center crimin scheme vio...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "df_text[\"text_stemmed\"] = df_text[\"text\"].apply(lambda text: stem_words(text))\n",
    "df_text.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>building wall usmexico border take literally y...</td>\n",
       "      <td>build wall usmexico border take liter year</td>\n",
       "      <td>building wall usmexico border take literally year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wisconsin pace double number layoffs year</td>\n",
       "      <td>wisconsin pace doubl number layoff year</td>\n",
       "      <td>wisconsin pace double number layoff year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>john mccain done nothing help vets</td>\n",
       "      <td>john mccain done noth help vet</td>\n",
       "      <td>john mccain done nothing help vet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suzanne bonamici supports plan cut choice medi...</td>\n",
       "      <td>suzann bonamici support plan cut choic medicar...</td>\n",
       "      <td>suzanne bonamici support plan cut choice medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asked reporter whether hes center criminal sch...</td>\n",
       "      <td>ask report whether he center crimin scheme vio...</td>\n",
       "      <td>asked reporter whether he center criminal sche...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  building wall usmexico border take literally y...   \n",
       "1          wisconsin pace double number layoffs year   \n",
       "2                 john mccain done nothing help vets   \n",
       "3  suzanne bonamici supports plan cut choice medi...   \n",
       "4  asked reporter whether hes center criminal sch...   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0         build wall usmexico border take liter year   \n",
       "1            wisconsin pace doubl number layoff year   \n",
       "2                     john mccain done noth help vet   \n",
       "3  suzann bonamici support plan cut choic medicar...   \n",
       "4  ask report whether he center crimin scheme vio...   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0  building wall usmexico border take literally year  \n",
       "1           wisconsin pace double number layoff year  \n",
       "2                  john mccain done nothing help vet  \n",
       "3  suzanne bonamici support plan cut choice medic...  \n",
       "4  asked reporter whether he center criminal sche...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "df_text['text_lemmatized'] = df_text['text'].apply(lambda text: lemmatize_words(text))\n",
    "df_text.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "866206d3ce38356be375f950e8c92408cdea91776d08b03ca687df0e81d3a33c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
